{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ljuyDL1Bmm1"
      },
      "source": [
        "Devin Short\n",
        "30 June 2023\n",
        "shortda@uw.edu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hGlrWSlBmm3"
      },
      "source": [
        "This is a tutorial demonstrating how to explore data parsed out of the catalogues. The idea is to understand what kind of content we've generated, get a feel for how well our current tools are working, and try improving them. This notebook requires functions from `reporting.py`, currently living in the scripts directory of the github repository.\n",
        "\n",
        "Let's import some packages and set parameters we'll use below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHPX5VgpBmm9"
      },
      "source": [
        "## <u>Testing new methods</u>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfDtn1T_Bmm-"
      },
      "source": [
        "If you can come up with a way to identify those author-to-author lines and separate them from the entries, you'll improve our data set. That's going to be pretty difficult though, so let's start with something easier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu3sSpInBmm-"
      },
      "source": [
        "Have a look at a sample of the longest entries:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9tqjBHnBmm-"
      },
      "source": [
        "The first two cases are relatively easy to handle. Let's start by finding the regular expressions our code uses to split entries apart and build on that to improve the current process. That code is documented in `Parsing_ECB_1912_wi23.ipynb`, currently living in the `scripts` directory of the github repository. In the section \"Splitting the Text into Entries\" in that notebook, I find the following process:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TW8kzJ1ABmm_",
        "outputId": "f2c5dc08-d5de-499a-ca26-04bce0cc1da6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total entries: 13918\n"
          ]
        }
      ],
      "source": [
        "# ALL CODE IN THIS CELL IS ADAPTED FROM Parsing_ECB_1912_wi23.ipynb\n",
        "import re\n",
        "\n",
        "# read the Hathi Trust OCR into memory\n",
        "with open(f'ecb_1919.txt', encoding='utf8') as f:\n",
        "    ocr_full_text = f.read()\n",
        "\n",
        "# Separate main text from the front matter of the catalogue (note the\n",
        "# string called ocr_main_text still has the back matter attached until\n",
        "# a later step)\n",
        "# Note python allows multiple assignment: the split operation below\n",
        "# creates a two-element list whose elements are then assigned to two\n",
        "# different variables\n",
        "ocr_front_matter, ocr_main_text = re.split(r'centimetres', ocr_full_text)\n",
        "\n",
        "appendix_pattern = (\n",
        "    r\"LEARNED SOCIETIES, PRINTING CLUBS, &c., WITH LISTS OF THEIR\\nPUBLICATIONS, 1918\\.\"\n",
        ")\n",
        "\n",
        "# Separate main text from the back matter of the catalogue\n",
        "ocr_main_text, ocr_back_matter = re.split(appendix_pattern, ocr_main_text)\n",
        "\n",
        "# Make a regular expression to capture headers at the top of each\n",
        "# catalogue page\n",
        "header_capital_letters = r\"^(?:[A-Z\\-\\'\\sÈ]+)\"\n",
        "header_pattern = r\"^#(?s:.*?){}(?s:.*?){}(?s:.*?){}$\".format(\n",
        "    header_capital_letters, header_capital_letters, header_capital_letters\n",
        ")\n",
        "\n",
        "# Split the main text into pages and strip the headers. According to\n",
        "# Parsing_ECB_1912_wi23.ipynb this method fails to remove six headers.\n",
        "pages = [\n",
        "    re.sub(header_pattern, '', page, flags=re.M)\n",
        "    for page in ocr_main_text.split('\\f')\n",
        "]\n",
        "\n",
        "# Now find all lines ending in 12 and insert a token to split on\n",
        "entries_by_page = [\n",
        "    re.sub(r'(\\W19\\.?$)', '\\\\1<ENTRY_CUT>', page, flags=re.M)\n",
        "    for page in pages\n",
        "]\n",
        "\n",
        "# Split on the token to create a list of lists where each element is\n",
        "# a list of entries on an individual page\n",
        "entries_by_page = [\n",
        "    re.split(r'<ENTRY_CUT>', page, flags=re.M)\n",
        "    for page in entries_by_page\n",
        "]\n",
        "\n",
        "print(f'total entries: {sum([len(p) for p in entries_by_page])}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYaEHt3ABmm_"
      },
      "source": [
        "Now let's test a new regular expression for splitting entries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VntA-EWdBmm_",
        "outputId": "acb0762a-aa0e-4045-ad90-eae33484b5db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total entries: 14646\n",
            "New entries on one page:\n",
            "\n",
            "\n",
            "\n",
            "2.\n",
            "a\n",
            "45. net\n",
            "Skinner (Walter R.)-The Oil and petroleum\n",
            "manual, 1919. 8vo. 81 x 54, pp. 276, 6s. net\n",
            "SKINNER, June '19\n",
            "\n",
            "Skipton (H. P. K.)-George Alfred Lefroy, Bishop\n",
            "of Calcutta. Cr. 8vo. 2d. net\n",
            "(19, Arthur Rd., Brixton)\n",
            "MISSIONARY LIT. SUPPLY, Oct.'19\n",
            "\n",
            "Skvortzov (J. V.)-Russian history. Vols. I and\n",
            "18mo. Ea. swd. is, net\n",
            "(78, Charing Cross Rd.) R. JASCHKE, June 19\n",
            "\n",
            "Sky pilot, Connor (R.) 6s. net\n",
            ". Apr.'19\n",
            "\n",
            "Sky pilot, Connor (R.) is. net July '19\n",
            "\n",
            "Sky pilot of No Man's Land, Connor (R.) 6s. net\n",
            "May '19\n",
            "\n",
            "Slack (Charles, Capt.) - Tourist's and student's\n",
            "manual of languages. 7th ed. 18mo. 61 x 4,\n",
            "pp. 128, 4s. 6d. net .. SIMPKIN, Aug. '19\n",
            "\n",
            "Slack (J. E.) and Dorey (A.)--\"At a glance.\"\n",
            "Ryl. 8vo. 91 x6, pp. 76, 78. 6d. net\n",
            "THE TECHNICAL PUBLG. CO., Mar. '19\n",
            "\n",
            "Sladen (Douglas)—Paul's wife ; or, The Ostriches :\n",
            "a romance of the awakening of Britain. Cr. 8vot\n",
            "74 X 5, pp. 256, 6s. 9d. net HUTCHINSON, Feb.'19\n",
            "\n",
            "Slater (E. I.)-Practical German grammar :\n",
            "course of lessons, with vocabulary, exercises and\n",
            "conversational sentences. Cr. 8vo. 77 x 43, pp.\n",
            "143, 25. 6d. net\n",
            ".PITMAN, Sep.'19\n",
            "\n",
            "Slator (Francis C.)-Settlers and sunbirds. 18mo.\n",
            "BLACKWOOD, Dec. '19\n",
            "\n",
            "Slater (Gilbert)\n",
            "-The Making of modern England.\n",
            "8vo. 8 X 54, pp. 319, 78. 6d. net\n",
            "CONSTABLE, Oct.'19\n",
            "\n",
            "Slattory (Margaret)-The Second line of defence :\n",
            "a plea for the men and women of to-morrow.\n",
            "Cr. 8vo. 74 X5, pp. 189, 5s. 6d. net\n",
            "REVELL, Aug. '19\n",
            "\n",
            "Slavery, Christianity and, Tabrum (A. H.) is. 3d.\n",
            "net\n",
            "Slavery, Christianity and, Cohen (C.) is. net\n",
            "Dec. '18\n",
            "\n",
            "Slavic Europe : Bibliography, Kerner (R. J.) 155.\n",
            "net\n",
            ".Mar.'19\n",
            "\n",
            "Slavic mythology : Mythology of all races, Gray\n",
            "(L. H.) and Moore (C. F.). Vol. 3.\n",
            "Feb. '19\n",
            "\n",
            "Slavonic literature, Anthology of modern. Selver\n",
            "(P.) 5s. net\n",
            "· June '10\n",
            "Sleath (Frederick)—The Seventh vial. Cr. 8vo.\n",
            "7} * 5, pp. 320, 6s. net ....H. JENKINS, Nov.'19\n",
            "\n",
            "Sleeman (J. L., Lt. Col.)-First principles of\n",
            "tactics and organization. Cr.\n",
            "8vo. 7 X 5,\n",
            "pp. 170, 6s. net\n",
            "...GALE & P., Oct. '19\n",
            "\n",
            "Sleeping beauty (The). Cr. 8vo. 7X41, pp. 64,\n",
            "IS. 3d. net. (Cinema ser.) .WESTALL, Nov.'19\n",
            "\n",
            "Sleeping partner, Willcocks (M. P.) 6s. 9d. net\n",
            "July '19\n",
            "\n",
            "Blesser (Henry H.)—The Nature of being :\n",
            "an\n",
            "essay in ontology. 8vo. 84 x 54, pp: 224,\n",
            "Ios. 6d. net.... ...ALLEN & U., Mar. '19\n",
            "\n",
            "Sliman Ben Ibrahim, see Dinet (E.) and Sliman\n",
            "Ben .\n",
            "8mall garden (The), and how best to utilise it.\n",
            "Cr. 8vo. 7 X5, pp. 44, swd. 9d.\n",
            "POULTRY WORLD, June ’19\n",
            "\n",
            "Small-holdings: My five-acre holding, Few (M.)\n",
            "35. 6d. net\n",
            ".Sep. '19\n",
            "\n",
            "Small-pox and vaccination, Half a century of,\n",
            "McVail (J. C.) 5s. 6d. net.\n",
            "..Nov.'19\n",
            "\n",
            "Small things, Deland (M.) 5s. net ..Nov. ’19\n",
            "\n",
            "Smallholders : 1,000 questions and answers,\n",
            "Brown (E. T.) is. 6d. net..\n",
            "..Nov. '19\n",
            "\n",
            "Smallholder's year book, 1919. 8vo. 81x51,\n",
            "pp. 223, Is. 6d. net\n",
            "(16-18, Henrietta St., W.C. 2)\n",
            "“ THE SMALLHOLDER,” Jan.'19\n",
            "\n",
            "Smasher, Gould (N.) is. net\n",
            "..Dec. '19\n",
            "\n",
            "• Smellie (Alexander)—The Well by the way :\n",
            "a second book of counsel and company for the\n",
            "Sabbath evening. Cr. 8vo. 7x44, pp. 271,\n",
            "45. 6d. net\n",
            ". MELROSE, Jan.'19\n",
            "\n",
            "Smith (A. Corbett)-The Problem of sex diseases.\n",
            "2nd ed. 98 x6, pp. 107, swd. 2s. 6d. net\n",
            "BALE, July ’19\n",
            "\n",
            "Smith (A. Corbett-) see also Corbett-Smith.\n",
            "Smith (Alexander)-A Summer in Skye. Ed., w.\n",
            "notes, and a letter of the author, hitherto\n",
            "unpublished, by Lauchlan Maclean Watt.\n",
            "18mo. 6° X4, pp. 343, Is. net\n",
            "ROUTLEDGE, Jan.'19\n",
            "\n",
            "Smith (Arthur D.)-The Audacious adventures\n",
            "of Miles McConaughy. Cr. 8vo. 74 x 5, pp. 256,\n",
            "6s.gd. net.....\n",
            "...SKEFFINGTON, Mar.'19\n",
            "\n",
            "Smith (Arthur H.) — Instructions for preparing\n",
            "saws for long band mills and band re-saws.\n",
            "Illus. 8vo. PP. 33\n",
            "(Rochdale) T. ROBINSON & SON, Apr.'19\n",
            "\n",
            "Smith (Arthur Hopewell) ed.—Normal and path.\n",
            "histology of mouth. 428. net........Feb.'19\n",
            "\n",
            "Smith (Bertram)-The “ Shilling\" curler. Cr. 8vo.\n",
            "RICHARDSON & W., Dec. '19\n",
            "\n",
            "Smith (C. Fox)-Rhymes of the Red Ensign.\n",
            "Cr. 8vo. 71 X 5, pp. 72, 5s. net\n",
            "HODDER & S., Feb. '19\n",
            "\n",
            "Smith (C. Fox) - Songs and chanties, 1914-1916.\n",
            "18mo. 61 X54, pp. 232, 6s. net\n",
            "E. MATHEWS, June'ig\n",
            "Smith (Sir Cecil H.)-War memorials. 8vo.\n",
            "81x55, pp. 16, swd. 3d.\n",
            "(Church House, S.W. I)\n",
            "CHURCH CRAFTS LEAGUE, Apr.'19\n",
            "\n",
            "Smith (Charles T.)-The Music of life : education\n",
            "for leisure and culture. With curricula evolved\n",
            "by experiment in an elementary school. 8vo.\n",
            "84x5), pp. 150, ós, net, swd. 4s. net\n",
            "P.S. KING, Feb.'19\n",
            "\n",
            "Smith (David)—The Life and letters of St. Paul,\n",
            "8vo. 9 x6, pp. 704, 21s. net HODDER, Dec. '19\n",
            "\n",
            "Smith (David N.)-- James Colin Maclehose, and\n",
            "Lieut., Rifle Brigade, 1897-1917. Ports. 8vo.\n",
            "pp. 39......(Glasgow) PRIVATELY PR., Dec. '18\n",
            "\n",
            "Smith (in London. .\n",
            ".Oct. '19\n",
            "\n",
            "| 78*48, pp. 40, 18. net\n",
            "3os, net\n",
            "Slippers of Cinderella, &c., Robertson on Go 7841. pp. 250, swd. 2.. DRANE, July 19\n",
            "\n",
            ".\n",
            "Dec. '19\n",
            "\n",
            "Sloan (J. P.) ed.-A Preliminary course in Sloan-\n",
            "Duployan phonography. Cr. 8vo. 77 x 48, pp.\n",
            "20, swd. 6à.\n",
            "(Ramsgate) SLOAN-DUPLOYAN PHONOGRAPHY,\n",
            "Aug. '19\n",
            "\n",
            "Sloan-Duployan phonograph, Prelim. course,\n",
            "Sloan (J. P.) 6d...\n",
            "..... Aug. '19\n",
            "\n",
            "Sluder (Greenfield) —Headaches and eye disorders\n",
            "of nasal origin. Illus. 8vo. pp. 272, 355. net\n",
            "KIMPTON, Dec. '18\n",
            "\n",
            "Small (Annie H.)-The Psalter and the life of\n",
            "prayer. Cr. 8vo. 78 x 57, pp. 176, swd. is. 6d.\n",
            "net\n",
            "..FOULIS, Nov.'19\n",
            "\n",
            "Small car handbook (The): all about economical\n",
            "motoring. By “ Candidus.\" Cr. 8vo. 71 x 5,\n",
            "pp. 225, 2s 6d. net\n",
            ". ILIFFE, Oct.'19\n",
            "\n",
            "Smith (E. Baldwin)-Early Christian iconography\n",
            "and a school of ivory carvers in Florence. Illus.\n",
            "4to. 10} * 8, pp. 292, 258. net (Princeton mono-\n",
            "graphs in art and archaeology)\n",
            "(Princeton Univ. Pr.) MILFORD, Nov. '19\n",
            "\n",
            "Smith (E. K. Seth-) see Seth-Smith.\n",
            "Smith (Ellen Ada)-The One in possession : a\n",
            "novel. Cr. 8vo. 71 X 5, pp. 282, 75. 6d. net\n",
            "JARROLDS, Oct. '19\n",
            "\n",
            "Smith (Ernest Newland)--Religion and the arts.\n",
            "Forew. by the Lord Bishop of Winchester.\n",
            "71 X54, pp. 32 RELIG. ART Soc., Feb. '19\n",
            "\n",
            "Smith (F., Maj.-Gen.)-A Veterinary history of\n",
            "the war in South Africa, 1899–1902. 4to.\n",
            "II X81, pp. 329, ios, 6d.\n",
            "(20, Fulham Rd., S.W.)\n",
            "H. & W. BROWN, Nov.'19\n",
            "\n",
            ")\n",
            ")\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# This cell assumes we're looking at the 1912 catalogue; try changing\n",
        "# this code (and the year parameter in the first code cell of the\n",
        "# notebook) to catch OCR mistakes for a different year.\n",
        "\n",
        "# create a list of possible values the OCR software might have created\n",
        "# when it ran into an 11 or 12 on the page\n",
        "ocr_interpretations_of_18 = [\n",
        "    '18'\n",
        "]\n",
        "ocr_interpretations_of_19 = [\n",
        "    '19',\n",
        "    'lg'\n",
        "]\n",
        "terminators = ocr_interpretations_of_18 + ocr_interpretations_of_19\n",
        "\n",
        "# modify the existing regex with our new options\n",
        "entry_terminator_regex = r'(\\W({})\\.?$)'.format('|'.join(terminators))\n",
        "\n",
        "# get a new set of entries the same way as above, but using the new\n",
        "# regular expression\n",
        "new_entries_by_page = [\n",
        "    re.sub(entry_terminator_regex, '\\\\1<ENTRY_CUT>', page, flags=re.M)\n",
        "    for page in pages\n",
        "]\n",
        "new_entries_by_page = [\n",
        "    re.split(r'<ENTRY_CUT>', page, flags=re.M)\n",
        "    for page in new_entries_by_page\n",
        "]\n",
        "\n",
        "print(f'total entries: {sum([len(p) for p in new_entries_by_page])}')\n",
        "\n",
        "#long_entries = clean_entries.loc[(lengths > 250)]\n",
        "#print(long_entries.sample(20))\n",
        "\n",
        "\n",
        "\n",
        "print('New entries on one page:')\n",
        "for item in new_entries_by_page[215]:\n",
        "  print(item)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXoGoCPaBmnA"
      },
      "source": [
        "OK, we might have found 157 entries that weren't caught with the previous splitting expression, meaning we might have gained 314 entries that were either not present or invalid in the previous data set. Let's see if that's really what happened."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIsj8y0yBmnA"
      },
      "outputs": [],
      "source": [
        "# It can be much more efficient to do things like check if elements in\n",
        "# one sequence exist in another using pandas objects rather than the\n",
        "# standard python library, so I flatten the lists of lists of entries\n",
        "# into pandas series containing all the entries.\n",
        "old_entries = pd.Series(\n",
        "    [e for page in entries_by_page for e in page],\n",
        "    dtype=pd.StringDtype()\n",
        ")\n",
        "new_entries = pd.Series(\n",
        "    [e for page in new_entries_by_page for e in page],\n",
        "    dtype=pd.StringDtype()\n",
        ")\n",
        "\n",
        "# strip nonprinting characters and replace all newlines in each entry\n",
        "# with spaces\n",
        "old_entries = old_entries.str.strip()\n",
        "new_entries = new_entries.str.strip()\n",
        "old_entries = old_entries.str.replace('\\n', ' ')\n",
        "new_entries = new_entries.str.replace('\\n', ' ')\n",
        "\n",
        "# Get new entries that don't exist in the old set\n",
        "new_entries = new_entries.loc[~new_entries.isin(old_entries)]\n",
        "\n",
        "print(f'number of new entries: {len(new_entries)}')\n",
        "\n",
        "# plot a histogram of lengths of the new entries\n",
        "fig2 = new_entries.map(len).hist(bins=range(0, 400, 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFZUUc8xBmnA"
      },
      "source": [
        "The histogram we started with covers nearly 20,000 entries. Here we have only 300, but the plot generated in the previous cell already looks extremely similar to the one at the top of the document. This means we can probably assume the entries we've produced here are just as good as the rest of the entries we're already capturing. Probably! I haven't actually looked at the new entries in detail, but it's 0200 and I need to finish this up."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlUPgnBiBmnA"
      },
      "source": [
        "## <u>Wrapping up</u>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVir5_hHBmnA"
      },
      "source": [
        "The goal here was to demonstrate how to play around with the data and the code for our summer project. The general method I followed was something like the following:\n",
        "1. Get some kind of overview of the output from our current parsing operations. I went with the size of the strings but there are all kinds of ways to do this. You could think about features of strings that have words in all caps and compare them to strings that don't have capitalized words (publishers in the author-first entries are almost always capitalized). You could start by exploring the dataframes, where the strings have been parsed out into specific fields, rather than thinking about whole entries. Explore the results we have and find something you think is interesting. If you can't think of a way to use that feature to explore the data, run it by one of your colleagues and see what they think. Your team is always your best asset!\n",
        "2. Use that view of the data to characterize what's working and what isn't. In this case it was clear that unreasonably short or long strings were going to have some errors, so I was able to look at those entries to see where there might be problems in the existing process.\n",
        "3. Find out which part of the existing code is relevant for the feature you're interested in. This part is probably going to be hard if you haven't had a much experience with programming. If it isn't obvious how to proceed after you've had a look at some of the scripts, ask me or Anna how to do what you want to do.\n",
        "4. See if you can modify the code to get different results.\n",
        "5. Use the same overview process you started with to compare your new result with the old one.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}